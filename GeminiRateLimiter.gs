/**
 * â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
 * GEMINI RATE LIMITER - Sistema de Controle de Taxa de RequisiÃ§Ãµes
 * â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
 *
 * Gerencia requisiÃ§Ãµes Ã  API Gemini para evitar rate limiting (429):
 * - Queue com throttling automÃ¡tico
 * - Backoff exponencial inteligente
 * - Cache de requisiÃ§Ãµes
 * - MÃ©tricas de uso
 *
 * LIMITES DA API GEMINI (Free Tier):
 * - 15 requests per minute (RPM)
 * - 1 million tokens per minute
 * - 1,500 requests per day
 *
 * @version 1.0.0
 * @date 2025-12-28
 */

/**
 * Sistema de Rate Limiting para API Gemini
 * @namespace GeminiRateLimiter
 */
const GeminiRateLimiter = {
  
  /**
   * ConfiguraÃ§Ãµes do rate limiter
   */
  CONFIG: {
    // MÃ¡ximo de requisiÃ§Ãµes por minuto (conservador para evitar 429)
    MAX_REQUESTS_PER_MINUTE: 12,
    
    // Delay mÃ­nimo entre requisiÃ§Ãµes (ms) - 5 segundos = 12 req/min
    MIN_DELAY_BETWEEN_REQUESTS: 5000,
    
    // Delay base para retry apÃ³s 429 (ms)
    BASE_RETRY_DELAY: 10000,
    
    // MÃ¡ximo de tentativas para uma requisiÃ§Ã£o
    MAX_RETRIES: 5,
    
    // Multiplicador para backoff exponencial
    BACKOFF_MULTIPLIER: 2,
    
    // Delay mÃ¡ximo para backoff (2 minutos)
    MAX_BACKOFF_DELAY: 120000,
    
    // TTL do cache em segundos (60 minutos - otimizado para reduzir chamadas)
    CACHE_TTL_SECONDS: 3600,
    
    // Habilitar cache de respostas
    ENABLE_CACHE: true,
    
    // Chave do cache no PropertiesService
    CACHE_KEY: 'GEMINI_RESPONSE_CACHE',
    
    // Chave para armazenar Ãºltima requisiÃ§Ã£o
    LAST_REQUEST_KEY: 'GEMINI_LAST_REQUEST_TIME',
    
    // Chave para mÃ©tricas diÃ¡rias
    METRICS_KEY: 'GEMINI_DAILY_METRICS'
  },
  
  /**
   * ObtÃ©m o timestamp da Ãºltima requisiÃ§Ã£o
   * @returns {number} Timestamp em ms
   */
  getLastRequestTime() {
    try {
      const props = PropertiesService.getScriptProperties();
      const lastTime = props.getProperty(this.CONFIG.LAST_REQUEST_KEY);
      return lastTime ? parseInt(lastTime, 10) : 0;
    } catch (e) {
      return 0;
    }
  },
  
  /**
   * Atualiza o timestamp da Ãºltima requisiÃ§Ã£o
   */
  setLastRequestTime() {
    try {
      const props = PropertiesService.getScriptProperties();
      props.setProperty(this.CONFIG.LAST_REQUEST_KEY, Date.now().toString());
    } catch (e) {
      Logger.log(`[GeminiRateLimiter] Erro ao salvar timestamp: ${e}`);
    }
  },
  
  /**
   * Aguarda o tempo necessÃ¡rio antes da prÃ³xima requisiÃ§Ã£o
   * @returns {number} Tempo aguardado em ms
   */
  waitForNextSlot() {
    const lastRequest = this.getLastRequestTime();
    const now = Date.now();
    const elapsed = now - lastRequest;
    const waitTime = Math.max(0, this.CONFIG.MIN_DELAY_BETWEEN_REQUESTS - elapsed);
    
    if (waitTime > 0) {
      Logger.log(`â³ [RateLimiter] Aguardando ${Math.round(waitTime/1000)}s antes da prÃ³xima requisiÃ§Ã£o...`);
      Utilities.sleep(waitTime);
    }
    
    this.setLastRequestTime();
    return waitTime;
  },
  
  /**
   * Calcula o delay para retry com backoff exponencial
   * @param {number} retryCount - NÃºmero da tentativa atual
   * @param {string} retryAfter - Valor do header Retry-After (opcional)
   * @returns {number} Delay em ms
   */
  calculateBackoffDelay(retryCount, retryAfter = null) {
    // Se a API forneceu um tempo especÃ­fico, use-o (com margem de seguranÃ§a)
    if (retryAfter) {
      const seconds = parseInt(retryAfter, 10);
      if (!isNaN(seconds)) {
        return (seconds + 5) * 1000; // Adiciona 5 segundos de margem
      }
    }
    
    // Backoff exponencial: 10s, 20s, 40s, 80s, 120s (max)
    const delay = this.CONFIG.BASE_RETRY_DELAY * Math.pow(this.CONFIG.BACKOFF_MULTIPLIER, retryCount - 1);
    return Math.min(delay, this.CONFIG.MAX_BACKOFF_DELAY);
  },
  
  /**
   * Gera uma chave de cache baseada no prompt
   * @param {string} prompt - O prompt da requisiÃ§Ã£o
   * @param {string} model - O modelo usado
   * @returns {string} Chave de cache
   */
  generateCacheKey(prompt, model) {
    // Usa um hash simples do prompt para criar a chave
    let hash = 0;
    const str = `${model}:${prompt}`;
    for (let i = 0; i < str.length; i++) {
      const char = str.charCodeAt(i);
      hash = ((hash << 5) - hash) + char;
      hash = hash & hash; // Convert to 32bit integer
    }
    return `cache_${Math.abs(hash).toString(36)}`;
  },
  
  /**
   * ObtÃ©m resposta do cache
   * @param {string} cacheKey - Chave do cache
   * @returns {object|null} Resposta cacheada ou null
   */
  getFromCache(cacheKey) {
    if (!this.CONFIG.ENABLE_CACHE) return null;
    
    try {
      const cache = CacheService.getScriptCache();
      const cached = cache.get(cacheKey);
      
      if (cached) {
        Logger.log(`âœ… [RateLimiter] Cache hit para ${cacheKey.substring(0, 20)}...`);
        this.updateMetrics('cache_hits');
        return JSON.parse(cached);
      }
    } catch (e) {
      Logger.log(`[RateLimiter] Erro ao ler cache: ${e}`);
    }
    
    return null;
  },
  
  /**
   * Salva resposta no cache
   * @param {string} cacheKey - Chave do cache
   * @param {object} response - Resposta para cachear
   */
  saveToCache(cacheKey, response) {
    if (!this.CONFIG.ENABLE_CACHE) return;
    
    try {
      const cache = CacheService.getScriptCache();
      cache.put(cacheKey, JSON.stringify(response), this.CONFIG.CACHE_TTL_SECONDS);
      Logger.log(`ğŸ’¾ [RateLimiter] Resposta cacheada: ${cacheKey.substring(0, 20)}...`);
    } catch (e) {
      Logger.log(`[RateLimiter] Erro ao salvar cache: ${e}`);
    }
  },
  
  /**
   * Atualiza mÃ©tricas de uso
   * @param {string} type - Tipo de mÃ©trica (requests, errors, cache_hits, rate_limits)
   */
  updateMetrics(type) {
    try {
      const props = PropertiesService.getScriptProperties();
      const today = new Date().toISOString().split('T')[0];
      const metricsKey = `${this.CONFIG.METRICS_KEY}_${today}`;
      
      let metrics = {};
      const stored = props.getProperty(metricsKey);
      if (stored) {
        metrics = JSON.parse(stored);
      } else {
        metrics = {
          date: today,
          requests: 0,
          errors: 0,
          cache_hits: 0,
          rate_limits: 0,
          total_wait_time_ms: 0
        };
      }
      
      metrics[type] = (metrics[type] || 0) + 1;
      props.setProperty(metricsKey, JSON.stringify(metrics));
      
    } catch (e) {
      // Ignora erros de mÃ©tricas para nÃ£o afetar funcionalidade principal
    }
  },
  
  /**
   * ObtÃ©m mÃ©tricas do dia atual
   * @returns {object} MÃ©tricas de uso
   */
  getMetrics() {
    try {
      const props = PropertiesService.getScriptProperties();
      const today = new Date().toISOString().split('T')[0];
      const metricsKey = `${this.CONFIG.METRICS_KEY}_${today}`;
      
      const stored = props.getProperty(metricsKey);
      if (stored) {
        return JSON.parse(stored);
      }
      
      return {
        date: today,
        requests: 0,
        errors: 0,
        cache_hits: 0,
        rate_limits: 0,
        total_wait_time_ms: 0
      };
    } catch (e) {
      return { error: e.message };
    }
  },
  
  /**
   * Executa uma requisiÃ§Ã£o com rate limiting e retry
   * @param {function} requestFn - FunÃ§Ã£o que executa a requisiÃ§Ã£o
   * @param {object} options - OpÃ§Ãµes de configuraÃ§Ã£o
   * @returns {object} Resultado da requisiÃ§Ã£o
   */
  executeWithRateLimit(requestFn, options = {}) {
    const startTime = Date.now();
    const maxRetries = options.maxRetries || this.CONFIG.MAX_RETRIES;
    const enableCache = options.enableCache !== false && this.CONFIG.ENABLE_CACHE;
    const cacheKey = options.cacheKey;
    
    // Verifica cache primeiro
    if (enableCache && cacheKey) {
      const cached = this.getFromCache(cacheKey);
      if (cached) {
        return {
          ...cached,
          fromCache: true,
          processingTime: Date.now() - startTime
        };
      }
    }
    
    let lastError = null;
    
    for (let attempt = 1; attempt <= maxRetries; attempt++) {
      try {
        // Aguarda slot disponÃ­vel (throttling)
        const waitedTime = this.waitForNextSlot();
        
        // Executa a requisiÃ§Ã£o
        this.updateMetrics('requests');
        const result = requestFn();
        
        // Verifica se houve rate limit
        if (result && result.errorCode === 429) {
          this.updateMetrics('rate_limits');
          
          if (attempt < maxRetries) {
            const retryAfter = result.retryAfter;
            const backoffDelay = this.calculateBackoffDelay(attempt, retryAfter);
            
            Logger.log(`âš ï¸ [RateLimiter] Rate limit (429) - Tentativa ${attempt}/${maxRetries}`);
            Logger.log(`â³ [RateLimiter] Aguardando ${Math.round(backoffDelay/1000)}s antes de retry...`);
            
            Utilities.sleep(backoffDelay);
            continue;
          }
        }
        
        // Sucesso - salva no cache e retorna
        if (result && result.success) {
          if (enableCache && cacheKey) {
            this.saveToCache(cacheKey, result);
          }
          
          return {
            ...result,
            fromCache: false,
            attempts: attempt,
            processingTime: Date.now() - startTime
          };
        }
        
        // Erro nÃ£o-429, registra e continua ou retorna
        lastError = result;
        
        if (result && result.errorCode && result.errorCode !== 429) {
          // Para erros que nÃ£o sÃ£o rate limit, nÃ£o faz retry
          this.updateMetrics('errors');
          return result;
        }
        
      } catch (error) {
        lastError = { success: false, error: error.toString() };
        this.updateMetrics('errors');
        
        if (attempt < maxRetries) {
          const backoffDelay = this.calculateBackoffDelay(attempt);
          Logger.log(`âŒ [RateLimiter] Erro na tentativa ${attempt}: ${error}`);
          Logger.log(`â³ [RateLimiter] Retry em ${Math.round(backoffDelay/1000)}s...`);
          Utilities.sleep(backoffDelay);
        }
      }
    }
    
    // Todas as tentativas falharam
    return {
      success: false,
      error: `Todas as ${maxRetries} tentativas falharam. Ãšltimo erro: ${lastError?.error || 'Desconhecido'}`,
      lastError: lastError,
      attempts: maxRetries,
      processingTime: Date.now() - startTime,
      suggestion: 'Tente novamente em alguns minutos ou use o modo offline.'
    };
  },
  
  /**
   * Limpa o cache
   */
  clearCache() {
    try {
      const cache = CacheService.getScriptCache();
      // CacheService nÃ£o tem mÃ©todo para limpar tudo, mas podemos resetar configuraÃ§Ãµes
      const props = PropertiesService.getScriptProperties();
      props.deleteProperty(this.CONFIG.LAST_REQUEST_KEY);
      
      return { success: true, message: 'Cache e configuraÃ§Ãµes resetados' };
    } catch (e) {
      return { success: false, error: e.message };
    }
  },
  
  /**
   * Reseta o rate limiter (Ãºtil apÃ³s perÃ­odo de cooldown)
   */
  reset() {
    try {
      const props = PropertiesService.getScriptProperties();
      props.deleteProperty(this.CONFIG.LAST_REQUEST_KEY);
      Logger.log('ğŸ”„ [RateLimiter] Rate limiter resetado');
      return { success: true };
    } catch (e) {
      return { success: false, error: e.message };
    }
  },
  
  /**
   * Verifica se Ã© seguro fazer uma requisiÃ§Ã£o agora
   * @returns {object} Status com tempo de espera estimado
   */
  checkStatus() {
    const lastRequest = this.getLastRequestTime();
    const now = Date.now();
    const elapsed = now - lastRequest;
    const waitTime = Math.max(0, this.CONFIG.MIN_DELAY_BETWEEN_REQUESTS - elapsed);
    
    return {
      canRequest: waitTime === 0,
      waitTimeMs: waitTime,
      waitTimeSec: Math.ceil(waitTime / 1000),
      lastRequestAgo: Math.round(elapsed / 1000),
      config: {
        minDelaySeconds: this.CONFIG.MIN_DELAY_BETWEEN_REQUESTS / 1000,
        maxRequestsPerMinute: this.CONFIG.MAX_REQUESTS_PER_MINUTE
      }
    };
  }
};


// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// INTEGRAÃ‡ÃƒO COM GEMINI AI SERVICE
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

/**
 * Wrapper para chamadas Gemini com rate limiting
 * Substitui chamadas diretas para adicionar throttling automÃ¡tico
 * 
 * @param {string} prompt - Prompt para a API
 * @param {object} options - OpÃ§Ãµes da requisiÃ§Ã£o
 * @returns {object} Resultado da API
 */
function callGeminiWithRateLimit(prompt, options = {}) {
  const model = options.model || GeminiAIService.DEFAULT_MODEL;
  const cacheKey = options.skipCache ? null : GeminiRateLimiter.generateCacheKey(prompt, model);
  
  return GeminiRateLimiter.executeWithRateLimit(
    () => GeminiAIService.callGemini(prompt, options),
    {
      cacheKey: cacheKey,
      enableCache: !options.skipCache,
      maxRetries: options.maxRetries || 5
    }
  );
}


// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// QUEUE SYSTEM - Processamento em Lote
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

/**
 * Sistema de Queue para processamento em lote de mÃºltiplas requisiÃ§Ãµes
 * @namespace GeminiRequestQueue
 */
const GeminiRequestQueue = {
  
  /**
   * Processa uma lista de requisiÃ§Ãµes em sequÃªncia com rate limiting
   * @param {Array} requests - Lista de objetos {prompt, options, id}
   * @param {function} onProgress - Callback chamado a cada requisiÃ§Ã£o processada
   * @returns {Array} Resultados de todas as requisiÃ§Ãµes
   */
  processQueue(requests, onProgress = null) {
    const results = [];
    const totalRequests = requests.length;
    const startTime = Date.now();
    
    Logger.log(`ğŸ“‹ [Queue] Iniciando processamento de ${totalRequests} requisiÃ§Ãµes`);
    Logger.log(`â±ï¸ [Queue] Tempo estimado: ${Math.ceil(totalRequests * 6 / 60)} minutos`);
    
    for (let i = 0; i < totalRequests; i++) {
      const request = requests[i];
      const requestId = request.id || `req_${i + 1}`;
      
      Logger.log(`\nğŸ”„ [Queue] Processando ${i + 1}/${totalRequests}: ${requestId}`);
      
      try {
        const result = callGeminiWithRateLimit(request.prompt, request.options || {});
        
        results.push({
          id: requestId,
          success: result.success,
          result: result,
          index: i
        });
        
        if (onProgress) {
          onProgress({
            current: i + 1,
            total: totalRequests,
            id: requestId,
            success: result.success,
            fromCache: result.fromCache
          });
        }
        
        Logger.log(`${result.success ? 'âœ…' : 'âŒ'} [Queue] ${requestId}: ${result.success ? 'Sucesso' : result.error}`);
        
      } catch (error) {
        results.push({
          id: requestId,
          success: false,
          error: error.toString(),
          index: i
        });
        
        Logger.log(`âŒ [Queue] ${requestId}: Erro - ${error}`);
      }
    }
    
    const totalTime = Date.now() - startTime;
    const successCount = results.filter(r => r.success).length;
    
    Logger.log(`\nğŸ“Š [Queue] Processamento concluÃ­do:`);
    Logger.log(`   Total: ${totalRequests}`);
    Logger.log(`   Sucesso: ${successCount}`);
    Logger.log(`   Falha: ${totalRequests - successCount}`);
    Logger.log(`   Tempo total: ${Math.round(totalTime / 1000)}s`);
    
    return {
      success: true,
      results: results,
      summary: {
        total: totalRequests,
        successful: successCount,
        failed: totalRequests - successCount,
        successRate: Math.round((successCount / totalRequests) * 100),
        totalTimeMs: totalTime,
        avgTimePerRequest: Math.round(totalTime / totalRequests)
      }
    };
  },
  
  /**
   * Processa requisiÃ§Ãµes dividindo em chunks com pausas entre eles
   * Ãštil para grandes volumes de requisiÃ§Ãµes
   * 
   * @param {Array} requests - Lista de requisiÃ§Ãµes
   * @param {number} chunkSize - Tamanho de cada chunk (padrÃ£o: 5)
   * @param {number} pauseBetweenChunks - Pausa entre chunks em ms (padrÃ£o: 30000)
   * @returns {Array} Resultados
   */
  processInChunks(requests, chunkSize = 5, pauseBetweenChunks = 30000) {
    const totalChunks = Math.ceil(requests.length / chunkSize);
    const allResults = [];
    
    Logger.log(`ğŸ“¦ [Queue] Processando ${requests.length} requisiÃ§Ãµes em ${totalChunks} chunks`);
    
    for (let chunk = 0; chunk < totalChunks; chunk++) {
      const start = chunk * chunkSize;
      const end = Math.min(start + chunkSize, requests.length);
      const chunkRequests = requests.slice(start, end);
      
      Logger.log(`\nğŸ“¦ [Queue] Chunk ${chunk + 1}/${totalChunks} (${chunkRequests.length} requisiÃ§Ãµes)`);
      
      const chunkResults = this.processQueue(chunkRequests);
      allResults.push(...chunkResults.results);
      
      // Pausa entre chunks (exceto no Ãºltimo)
      if (chunk < totalChunks - 1) {
        Logger.log(`â¸ï¸ [Queue] Pausa de ${pauseBetweenChunks/1000}s entre chunks...`);
        Utilities.sleep(pauseBetweenChunks);
      }
    }
    
    const successCount = allResults.filter(r => r.success).length;
    
    return {
      success: true,
      results: allResults,
      summary: {
        total: requests.length,
        successful: successCount,
        failed: requests.length - successCount,
        successRate: Math.round((successCount / requests.length) * 100),
        chunks: totalChunks
      }
    };
  }
};


// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// API FUNCTIONS - Expostas para o Frontend e Testes
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

/**
 * ObtÃ©m status do rate limiter
 */
function apiRateLimiterStatus() {
  return GeminiRateLimiter.checkStatus();
}

/**
 * ObtÃ©m mÃ©tricas de uso do dia
 */
function apiRateLimiterMetrics() {
  return GeminiRateLimiter.getMetrics();
}

/**
 * Reseta o rate limiter
 */
function apiRateLimiterReset() {
  return GeminiRateLimiter.reset();
}

/**
 * Limpa o cache de respostas
 */
function apiRateLimiterClearCache() {
  return GeminiRateLimiter.clearCache();
}

/**
 * Processa mÃºltiplas requisiÃ§Ãµes em queue
 * @param {Array} requests - Array de {prompt, options, id}
 */
function apiProcessGeminiQueue(requests) {
  return GeminiRequestQueue.processQueue(requests);
}


// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// TESTE DO RATE LIMITER
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

/**
 * FunÃ§Ã£o de teste para validar o rate limiter
 */
function testRateLimiter() {
  Logger.log('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•');
  Logger.log('    TESTE DO GEMINI RATE LIMITER');
  Logger.log('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•');
  
  // 1. Verifica status
  Logger.log('\n1. STATUS DO RATE LIMITER:');
  const status = GeminiRateLimiter.checkStatus();
  Logger.log(JSON.stringify(status, null, 2));
  
  // 2. Testa mÃ©tricas
  Logger.log('\n2. MÃ‰TRICAS DO DIA:');
  const metrics = GeminiRateLimiter.getMetrics();
  Logger.log(JSON.stringify(metrics, null, 2));
  
  // 3. Testa requisiÃ§Ã£o simples com rate limiting
  Logger.log('\n3. TESTE DE REQUISIÃ‡ÃƒO COM RATE LIMITING:');
  
  if (GeminiAIService.isConfigured()) {
    const result = callGeminiWithRateLimit('Responda apenas: "OK"', {
      maxTokens: 10
    });
    Logger.log(`Sucesso: ${result.success}`);
    Logger.log(`Do cache: ${result.fromCache || false}`);
    Logger.log(`Tentativas: ${result.attempts || 1}`);
    Logger.log(`Tempo: ${result.processingTime}ms`);
  } else {
    Logger.log('âš ï¸ API Gemini nÃ£o configurada');
  }
  
  // 4. MÃ©tricas atualizadas
  Logger.log('\n4. MÃ‰TRICAS ATUALIZADAS:');
  const metricsAfter = GeminiRateLimiter.getMetrics();
  Logger.log(JSON.stringify(metricsAfter, null, 2));
  
  Logger.log('\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•');
  Logger.log('    TESTE CONCLUÃDO');
  Logger.log('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•');
  
  return { success: true, status, metrics: metricsAfter };
}


/**
 * Teste de queue com mÃºltiplas requisiÃ§Ãµes
 * ATENÃ‡ÃƒO: Vai consumir vÃ¡rias requisiÃ§Ãµes da API
 */
function testRateLimiterQueue() {
  Logger.log('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•');
  Logger.log('    TESTE DE QUEUE COM RATE LIMITING');
  Logger.log('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•');
  
  // Cria 3 requisiÃ§Ãµes de teste
  const requests = [
    { id: 'test_1', prompt: 'Responda apenas: "OlÃ¡ 1"', options: { maxTokens: 10 } },
    { id: 'test_2', prompt: 'Responda apenas: "OlÃ¡ 2"', options: { maxTokens: 10 } },
    { id: 'test_3', prompt: 'Responda apenas: "OlÃ¡ 3"', options: { maxTokens: 10 } }
  ];
  
  const result = GeminiRequestQueue.processQueue(requests, (progress) => {
    Logger.log(`ğŸ“Š Progresso: ${progress.current}/${progress.total} - ${progress.id}`);
  });
  
  Logger.log('\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•');
  Logger.log('    RESUMO DO TESTE');
  Logger.log('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•');
  Logger.log(JSON.stringify(result.summary, null, 2));
  
  return result;
}
